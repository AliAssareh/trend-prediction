{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3319d1bf-5933-4c48-b70f-12725cdc452a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step1) Import the raw data and preprocess them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f95e7f1-8417-434f-b6d4-8fbd92068144",
   "metadata": {},
   "source": [
    "## I) Regular exogenous data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93850c1f-5056-47cf-b5f5-be0833d8a51a",
   "metadata": {},
   "source": [
    "First we recreate the higher timeframes form existing lower ones and save them in the $\\color{red}{\\text{RepairedExoData}}$ folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5717683c-e0f4-47c4-bb43-f1d9dc872b8f",
   "metadata": {},
   "source": [
    "Second we calculate all the available indicators using these data with proper colprefix and then we interpolate the missing candles with ZeroOrderHold and save the result in the $\\color{red}{\\text{PreprocessedData}}$ folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8c5c92-9abb-447e-a198-ff3c83104273",
   "metadata": {
    "tags": []
   },
   "source": [
    "## II) Endogenous data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f967498c-3dae-4119-9801-73525b9bb0b5",
   "metadata": {},
   "source": [
    "### Preprocessing the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72083943-3e01-4b92-b69f-09be38bd2f91",
   "metadata": {},
   "source": [
    "First we interpolate the 1m data to use it for up_first detection of higher time frame data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002e7ea0-cd07-4eb9-ba04-e31043f8e101",
   "metadata": {},
   "source": [
    "Second we call the BtcPreprocessor class on which ever timeframe data we want to use, this class interpolates the missing candles, addes the up_first and calculated all the indicators. then it saves two versions of the endogenous_features in the $\\color{red}{\\text{PreprocessedData}}$ folder (one without any dropping to calculate the targets from it later, and one which drops the first 70 and last 1 candles to be used with target1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c20954-55ad-4774-8932-90e66a697f87",
   "metadata": {},
   "source": [
    "### Target definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f43134-0752-4610-930b-4fbbccef72ba",
   "metadata": {},
   "source": [
    "Third we call the TargetExtractor which calculates the target1 based on kf, from endogenous_features without any drops.\n",
    "then we save the targets in the $\\color{red}{\\text{PreprocessedData}}$ folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fc0010-6d9e-410d-9e8b-1283183403c7",
   "metadata": {},
   "source": [
    "## III) Mixing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024e65d0-8d2c-4645-b737-ff1e87c30b56",
   "metadata": {},
   "source": [
    "The DataMixer class takes both the target, timeframe and exogenous args and $\\color{red}{\\underline{\\color{white}{\\text{df_name}}}}$ arg, the first three are used to choose the proper dfs from PreprocessedData folder and the last one is used to save the generated df.\n",
    "\n",
    "In this step we just call the mixer function with proper first_candle and last_candle ($\\color{lightblue}{\\text{given in the Available data notebook}}$) to crop the common part of the data and desired Exogenous arg to mix and save just the endogenous or mix of endogenous and the corresponding exogenous data into $\\color{red}{\\underline{\\color{white}{\\text{df_name}}}}$_features and $\\color{red}{\\underline{\\color{white}{\\text{df_name}}}}$_labels file in the $\\color{red}{\\text{MixedData}}$ folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2718a968-d2d1-4f5e-8cfb-2708764cf2a5",
   "metadata": {},
   "source": [
    "## IV) Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5379b4a-a95b-499c-a258-a3f4e4c4e789",
   "metadata": {},
   "source": [
    "### FeatureEngineer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31734eb-74ee-4d5f-bef7-fb33179c12fd",
   "metadata": {},
   "source": [
    "FeatureEngineer class takes both df_name and model name arguments because we might have multiple models with different names that use the same features and targets, which is specified through the df_name arg.\n",
    "\n",
    "this class loads the dfs through df_name and writes the most appropariate features for the given target in the $\\color{red}{\\text{models_feature_names_files}}$ with the given model_name arg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81866420-7b6e-46c6-9900-9f7bc260bf87",
   "metadata": {},
   "source": [
    "### FeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba6645-5598-451f-b636-742ab7d0033c",
   "metadata": {},
   "source": [
    "FeatureExtractor class first takes the $\\color{red}{\\underline{\\color{white}{\\text{df_name}}}}$ arg to initiate, in this step the features and the targets are loaded in the generated instance.\n",
    "\n",
    "Then when you want to get the features and the labels you must give the \"extract_features\" function the intended $\\color{red}{\\underline{\\color{white}{\\text{model_name}}}}$, so that the feature extractor read the models features_names and separate the selected features.\n",
    "\n",
    "if you choose to set save arg of the function to True, the function would also save the extracted features and corresponding labels in the $\\color{red}{\\text{ProcessedData}}$ folder with the given $\\color{red}{\\underline{\\color{white}{\\text{model_name}}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26df246-fbca-49a8-baa7-bc3e6c686dd3",
   "metadata": {},
   "source": [
    "### TrainTestValidationLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c83a618-65fd-401d-9970-a62fd72406d5",
   "metadata": {},
   "source": [
    "TrainTestValidationLoader, takes the ready_features or the corresponding model_name and prepares the data for training the model you want to train. you can either use its functions to load the data for LSTM networks or use the classes variables directly if you want to reshape them in another way.\n",
    "If you want to use data from different timeframes in your prediction the original_time_frame parameter should be specified, the timeframe of the provided data would be implied from the first two rows of the features_df."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aa6972-01aa-4373-81ed-0563bbdcad76",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbe7f3b4-ff00-49bb-b1de-d4cd19aba175",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff798f1d-89c1-4a68-928b-b44ceeaf5853",
   "metadata": {},
   "source": [
    "# Step2) Process the data for the desired model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e1dad6-4e68-45d0-89c6-59b894a22aa3",
   "metadata": {},
   "source": [
    "First we call the FeatureEngineer with proper argumans of use_exogenous_data and model_name to remove the features with too much correlation and save the remaining features names in a file with the given model name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f4d53-fca4-405e-9863-b5e3a63f5fd1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8b30d0a-3089-4cf9-8bb7-b877a6b8b029",
   "metadata": {},
   "source": [
    "Forth FeatureEngineer operates on BTCUSDT_xm_data_with_up_first.It first calcualtes all the stationary indicators and then does a feature selection based on mutual information between features and target variable and correlation between features.\n",
    "The last row of features is droped because for the last row, we dont have any label.Also The first 70 rows of features and targets are droped too, since during the calculation of indicators some of indicators need the previous data to be generated.\n",
    "If you want to use data from different timeframes in your prediction the timeframe and original timeframe in minutes parameters are going to be different and also more data is going to be removed the beggining and the end of features and labels so that all timeframes contain the same data.\n",
    "The output of this process is the BTCUSDT_xm_all_features at PreprocessedData and BTCUSDT_xm_smoothed_changes at ProcessedData plus the features_of_model_name.txt at models_feature_names_files folder.\n",
    "\n",
    "Fourth FeatureExtractor takes the BTCUSDT_xm_all_features and features_of_model_name.txt file and extracts the chosen features, if the save parameter is set to true, the extracted data would be saved as BTCUSDT_xm_ready_features at ProcessedData folder.\n",
    "\n",
    "Fifth TrainTestValidationLoader, takes the ready_features or its address and the targets address and prepares the data for training the model you want to train. you can ither use its functions to load the data for LSTM networks or use the classes variables directly if you want to reshape them in another way.\n",
    "If you want to use data from different timeframes in your prediction the original_time_frame parameter should be specified, the timeframe of the provided data would be implied from the first two rows of the df."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b050edf9-07d1-4634-b400-fbb8ee05238e",
   "metadata": {},
   "source": [
    "# Step2) Import the predicted values by the networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa5bb10-fb6e-4a19-a8b0-dec9d47ee289",
   "metadata": {},
   "source": [
    "## Data that is already separated into train, test and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85129383-f9c6-4a77-bd86-2320f4b02698",
   "metadata": {},
   "source": [
    "If you want to try a rule based strategy you could use \"get_predictions_dfs\" to get train, test, and validation data separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e32e40-b0ee-4f0e-8075-216328cb3344",
   "metadata": {},
   "source": [
    "## All of the data in one df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b3c8f0-971e-4f76-b43e-9dfe00e956c3",
   "metadata": {},
   "source": [
    "If you use \"get_predictions_df\" all of the data would be provided in one single df, this option is more preferable if you want to train a ML model to predict the market based on the trend predictions of the previous model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac72ddb-9019-4db1-8d99-b75412eae9e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32053965-b5ef-4d46-af2a-6bf62343fd5f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77e732be-7cc7-4cfe-bd36-978c5d8ade28",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f1cb532-69ac-4674-a805-d78b14e216b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1507e510-a1ea-4cd1-90e9-2ed861f63eb6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd6ddb9e-bb42-4164-8166-bc6ad024de8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "102d55b6-f0a9-4088-9fb2-711caf305444",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a67c5ba-805e-4295-bc23-14667d2ac8c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3378d654-42ac-4287-9ddc-86567198ad36",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2aa95b3-4873-424d-9e73-a895ed3b31dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b0e830e-7850-47d5-9094-bf8379590179",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19f9d0e1-fb5b-48c7-9a69-6b55b9aac6f5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c73a43df-237b-420d-8924-1d6b4d6259be",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c555efc-5076-45fb-96ca-eb0e51c4d2dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b916e47-2c40-49c1-b9c0-b026c932c597",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4aaa0d8c-4e97-4362-a1ad-73fa67098e7f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
